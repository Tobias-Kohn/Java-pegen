"""
This is a Java backaned for the Python PEG parser generator (pegen).  It is based
primarily on the Python backend and intended to generate a parser for Jython so 
as to support Python syntax 3.9+.

Find the full *pegen* Parser generator here:
  https://github.com/we-like-parsers/pegen

Authors:
- Tobias Kohn
"""
from __future__ import annotations

import ast
import contextlib
#import json
import re
import token
from typing import Any, Dict, Optional, IO, Iterator, List, Set, Text, Tuple

from pegen.grammar import (
    Cut,
    GrammarVisitor,
    NameLeaf,
    StringLeaf,
    Rhs,
    NamedItem,
    Lookahead,
    PositiveLookahead,
    NegativeLookahead,
    Opt,
    Repeat0,
    Repeat1,
    Gather,
    Group,
    Rule,
    Alt,
)
from pegen import grammar
from pegen.parser_generator import ParserGenerator

from pegen.action_translator import translate_action

MODULE_PREFIX = """\
/*
 * @generated by pegen from {filename}
 */
package org.python.parser;

import java.util.ArrayList;
import java.util.Arrays;
import java.util.HashMap;
import java.util.HashSet;
import java.util.List;
import java.util.Map;
import java.util.Set;

"""
MODULE_SUFFIX = """
"""

CLASS_PREFIX = """\
private static class Memo<T_> {
    public final T_ item;
    public int end_mark;
    
    Memo(T_ item, int end_mark) {
        this.item = item;
        this.end_mark = end_mark;
    }
    
    @Override
    public String toString() {
        if (item != null)
            return item.toString() + ":~" + end_mark;
        else
            return "<null>:~" + end_mark;
    }
}
"""

# Since we are generating the parser for Jython, we could use ``PyObject`` here.  However,
# using a generic type parameter means that the parser module is only loosely coupled and
# less tied to the design of Jython itself.
TYPE = "T"


class JavaCallMakerVisitor(GrammarVisitor):
    def __init__(self, parser_generator: JavaParserGenerator):
        self.gen = parser_generator
        self.keywords: Set[str] = set()
        self.cache: Dict[Any, Any] = {}

    def visit_NameLeaf(self, node: NameLeaf) -> Tuple[Optional[str], str]:
        name = node.value
        if name in ("NAME", "NUMBER", "STRING", "OP"):
            name = name.lower()
            return name, f"this.{name}()"
        if name in ("NEWLINE", "DEDENT", "INDENT", "ENDMARKER", "ASYNC", "AWAIT", "TYPE_COMMENT"):
            return None, f"this.expect(TokenType.{name})"
        if name in ("default",):
            return name + '_', f"this.{name}_()"
        if name.startswith("invalid_") or name.startswith("incorrect_"):
            return None, f"this.{name}()"
        return name, f"this.{name}()"

    def visit_StringLeaf(self, node: StringLeaf) -> Tuple[str, str]:
        val = ast.literal_eval(node.value)
        if self.gen.use_reserved_words:
            if re.match(r"[a-zA-Z_]\w*\Z", val):  # This is a keyword
                self.keywords.add(val)
                return None, f"this.expectKeyword(\"{val}\")"
        if node.value and len(node.value) > 3 and node.value[0] == "'" == node.value[-1]:
            return "literal", f"this.expectStr(\"{node.value[1:-1]}\")"
        return "literal", f"this.expectStr({node.value})"

    def visit_Rhs(self, node: Rhs) -> Tuple[Optional[str], str]:
        if node in self.cache:
            return self.cache[node]
        if len(node.alts) == 1 and len(node.alts[0].items) == 1:
            self.cache[node] = self.visit(node.alts[0].items[0])
        else:
            name = self.gen.name_node(node)
            self.cache[node] = name, f"this.{name}()"
        return self.cache[node]

    def visit_NamedItem(self, node: NamedItem) -> Tuple[Optional[str], str]:
        name, call = self.visit(node.item)
        if node.name:
            name = node.name
        return name, call

    def lookahead_call_helper(self, node: Lookahead) -> Tuple[str, str]:
        name, call = self.visit(node.node)
        head, tail = call.split("(", 1)
        assert tail[-1] == ")"
        tail = tail[:-1]
        return head, tail

    def visit_PositiveLookahead(self, node: PositiveLookahead) -> Tuple[None, str]:
        head, tail = self.lookahead_call_helper(node)
        if head == "this.expect" and tail and tail[0] in "'\"":
            head = "this::expectStr"
        elif head.startswith("this."):
            head = "this::" + head[5:]
        if tail != "":
            return None, f"this.positive_lookahead({head}, {tail})"
        else:
            return None, f"this.positive_lookahead({head})"

    def visit_NegativeLookahead(self, node: NegativeLookahead) -> Tuple[None, str]:
        head, tail = self.lookahead_call_helper(node)
        if head == "this.expect" and tail and tail[0] in "'\"":
            head = "this::expectStr"
        elif head.startswith("this."):
            head = "this::" + head[5:]
        if tail != "":
            return None, f"this.negative_lookahead({head}, {tail})"
        else:
            return None, f"this.negative_lookahead({head})"

    def visit_Opt(self, node: Opt) -> Tuple[str, str]:
        name, call = self.visit(node.node)
        # Note trailing comma (the call may already have one comma
        # at the end, for example when rules have both repeat0 and optional
        # markers, e.g: [rule*])
        return name, call

    def visit_Repeat0(self, node: Repeat0) -> Tuple[str, str]:
        if node in self.cache:
            return self.cache[node]
        name = self.gen.name_loop(node.node, False)
        self.cache[node] = name, f"this.{name}()"  # Also a trailing comma!
        return self.cache[node]

    def visit_Repeat1(self, node: Repeat1) -> Tuple[str, str]:
        if node in self.cache:
            return self.cache[node]
        name = self.gen.name_loop(node.node, True)
        self.cache[node] = name, f"null_if_empty(this.{name}())"  # But no trailing comma here!
        return self.cache[node]

    def visit_Gather(self, node: Gather) -> Tuple[str, str]:
        if node in self.cache:
            return self.cache[node]
        name = self.gen.name_gather(node)
        self.cache[node] = name, f"this.{name}()"  # No trailing comma here either!
        return self.cache[node]

    def visit_Group(self, node: Group) -> Tuple[Optional[str], str]:
        return self.visit(node.rhs)

    def visit_Cut(self, node: Cut) -> Tuple[str, str]:
        return "cut", "true"


class JavaParserGenerator(ParserGenerator, GrammarVisitor):
    def __init__(
        self,
        grammar: grammar.Grammar,
        file: Optional[IO[Text]],
        *,
        tokens: Dict[int, str] = token.tok_name,
        skip_actions: bool = False,
    ):
        keywords = grammar.metas.get("keywords")
        self.use_reserved_words = self.parse_bool(keywords, "keywords", True)
        if skip_actions and ("start" not in grammar.rules and "trailer" not in grammar.metas):
            first_rule = next(iter(grammar.rules))
            grammar.rules["start"] = Rule(
                "start", None, Rhs([Alt([NamedItem(None, NameLeaf(first_rule))])])
            )
        super().__init__(grammar, tokens, file)
        self.skip_actions = skip_actions
        self.callmakervisitor: JavaCallMakerVisitor = JavaCallMakerVisitor(self)
        # We need the *ALT-context* stack because of the typing required in Java.  For each
        # local variable we need to know the type and declare the variable before its use
        # in the IF text expression.  Furthermore, if it returns a Token, say, we may need
        # to wrap it later on so as to return a AST-node object.
        self._alt_context_stack: List[List[str]] = []
        
    @contextlib.contextmanager
    def alt_context(self) -> Iterator[None]:
        self._alt_context_stack.append([{}, []])
        yield
        self._alt_context_stack.pop()
        
    def alt_print(self, value):
        self._alt_context_stack[-1][1].append(value)
        
    def alt_print_tests(self):
        txt = self._alt_context_stack[-1][1]
        with self.indent():
            first = True
            for item in txt:
                if first:
                    first = False
                else:
                    self.print("&&")
                self.print(item)
            

    def alt_print_types(self):
        _types = self._alt_context_stack[-1][0]
        for n in _types:
            if n != "cut":
                self.print(f"{_types[n]} {n};")
            
    def _is_token_type(self, name) -> bool:
        x = self._alt_context_stack[-1][0]
        if name in x:
            _type = x[name]
            return _type == "Token"
        else:
            return False
            
    def set_local_type(self, name, _type):
        self._alt_context_stack[-1][0][name] = _type

    def parse_bool(self, value: Optional[str], name: str, default: bool) -> bool:
        if value is None:
            return default
        matches = {
            "false": False,
            "true": True,
        }
        cleaned = value.strip().lower()
        if cleaned not in matches:
            print(f"Unrecognized meta directive @{name} {value}")
        return matches.get(cleaned, default)

    def generate(self, filename: str) -> None:
        self.print_header(filename)

        while self.todo:
            for rulename, rule in list(self.todo.items()):
                del self.todo[rulename]
                self.print()
                with self.indent():
                    self.visit(rule)

        self.print_keywords()
        self.print_trailer()

    def print_keywords(self) -> None:
        """
        Generates a list of the keywords used by the parser and prints that list to the
        generated Java class.  It overrides the Parser's ``isKeyword(s)`` method, which
        returns true if the string ``s`` is a keyword.
        """
        keywords = self.callmakervisitor.keywords
        self.print()
        with self.indent():
            if not keywords:
                self.print("@Override")
                self.print("protected boolean isKeyword(String name) {")
                with self.indent():
                    self.print("return false;");
                self.print("}")
            else:
                self.print("private final Set<String> _keywords = new HashSet<>(Arrays.asList(")
                with self.indent():
                    kws = sorted(keywords)
                    for kw in kws[:-1]:
                        self.print(f"\"{kw}\",")
                    self.print(f"\"{kws[-1]}\"")
                self.print("));")
                self.print()
                self.print("@Override")
                self.print("protected boolean isKeyword(String name) {")
                with self.indent():
                    self.print("return _keywords.contains(name);");
                self.print("}")

    def print_header(self, filename: str) -> None:
        """
        Generates the header of the file by including the header defined above and adding the
        definition of the class ``GenreatedParser<T>``.
        """
        header = MODULE_PREFIX
        if header is not None:
            self.print(header.rstrip("\n").format(filename=filename))
        if not self.skip_actions:
            subheader = self.grammar.metas.get("subheader", "")
            if subheader:
                self.print(subheader.format(filename=filename))
        self.print("")
        self.print(f"class GeneratedParser<{TYPE}> extends Parser<{TYPE}> {{")
        with self.indent():
            self.print("")
            self.print(f"GeneratedParser(Tokenizer tokenizer, String filename, boolean verbose, AstFactory<{TYPE}> ast) {{")
            with self.indent():
                self.print("super(tokenizer, filename, verbose, ast);")
            self.print("}")
            self.print("")
            for line in CLASS_PREFIX.splitlines():
                self.print(line)

    def print_trailer(self) -> None:
        """
        Generates the trailer of the file.  This is usually the closing brace of the class definition.
        """
        self.print("}")
        trailer = MODULE_SUFFIX
        if trailer is not None:
            self.print(trailer.rstrip("\n"))
            
    def _has_seq_action(self, node) -> bool:
        if isinstance(node, Opt):
            node = node.node
        if isinstance(node, Rhs) and len(node.alts) == 1:
            node = node.alts[0]
        if isinstance(node, Alt):
            if node.action:
                action = node.action
                if action.startswith("_PyPegen_seq_insert_in_front"):
                    return True
                else:
                    dtype = None
                    for item in node.items:
                        if isinstance(item, NamedItem):
                            if item.name == action and isinstance(item.item, NameLeaf) and self._is_seq(item.item.value):
                                return True
        return False

    def visit_Rule(self, node: Rule) -> None:
        """
        Each rule produces a protected method that either returns an element or
        a sequence/array of type T.  We ignore the types found in the grammar 
        file (which are C-types), except for a "seq"-element indicating a
        sequence rather than an individual element.
        """
        is_loop = node.is_loop()
        is_gather = node.is_gather()
        rhs = node.flatten()
        if is_loop or is_gather or (node.type and "seq" in node.type):
            node_type = f"{TYPE}[]"
        else:
            if self._has_seq_action(rhs):
                node_type = f"{TYPE}[]"
            else:
                node_type = TYPE
        name = node.name
        if name in ("default", ):
            name += '_'
        self.print(f"private final Map<Integer, Memo<{node_type}>> {node.name}_cache = new HashMap<>();")
        self.print("")
        self.print(f"protected {node_type} {name}() {{")
        with self.indent():
            if node.left_recursive:
                if node.leader:
                    self.print("int p = this.mark();")
                    self.print(f"Memo<{node_type}> info = {node.name}_cache.get(p);")
                    self.print("if (info != null) {")
                    with self.indent():
                        self.print(f"log(\"{node.name}() [cached]-> \" + info.toString());")
                        self.print("this.reset(info.end_mark);")
                        self.print("return info.item;");
                    self.print("}")
                    self.print(f"logl(\"{node.name}() ...\");")
                    self.print(f"{node_type} last_result = null;")
                    self.print("int last_mark = p;")
                    self.print("int depth = 0;")
                    self.print(f"{node.name}_cache.put(p, new Memo<>(null, p));")
                    self.print(f"log(\"recursive {node.name}() at \" + p + \" depth \" + depth);")
                    self.print("while (true) {")
                    with self.indent():
                        self.print("this.reset(p);")
                        self.print("this._level += 1;")
                        self.print(f"{node_type} result = _{name}();")
                        self.print("int end_mark = this.mark();")
                        self.print("depth += 1;")
                        self.print("this._level -= 1;")
                        self.print(f"log(\"recursive {node.name}() at \" + p + \" depth \" + depth + \": \", result);")
                        self.print("if (result == null || end_mark <= last_mark)")
                        self.print("    break;")
                        self.print("last_result = result;")
                        self.print("last_mark = end_mark;")
                        self.print(f"{node.name}_cache.put(p, new Memo<>(result, end_mark));")
                    self.print("}")
                    self.print("this.reset(last_mark);")
                    self.print("if (last_result != null) {")
                    with self.indent():
                        self.print("last_mark = this.mark();")
                    self.print("} else {")
                    with self.indent():
                        self.print("last_mark = p;")
                        self.print("this.reset(last_mark);")
                    self.print("}")
                    self.print(f"log(\"{node.name}() [fresh]-> \", last_result);")
                    self.print(f"{node.name}_cache.put(p, new Memo<>(last_result, last_mark));")
                    self.print(f"return last_result;")
                else:
                    self.print(f"return _{node.name}();")
            else:
                self.print("int p = this.mark();")
                self.print(f"Memo<{node_type}> info = {node.name}_cache.get(p);")
                self.print("if (info != null) {")
                with self.indent():
                    self.print(f"log(\"{node.name}() [cached]-> \" + info.toString());")
                    self.print("this.reset(info.end_mark);")
                    self.print("return info.item;");
                self.print("}")
                self.print(f"logl(\"{node.name}() ...\");")
                self.print("this._level += 1;")
                self.print(f"{node_type} result = _{name}();")
                self.print("this._level -= 1;")
                self.print(f"log(\"{node.name}() [fresh]-> \", result);")
                self.print("if (result != null) {")
                with self.indent():
                    self.print(f"{node.name}_cache.put(p, new Memo<>(result, this.mark()));")
                self.print("}")
                self.print(f"return result;")
        self.print("}")
        self.print("")
        self.print(f"private {node_type} _{name}() {{")
        with self.indent():
            self.print(f"// {node.name}: {rhs}")
            if node.nullable:
                self.print(f"// nullable={node.nullable}")
            if node.type:
                self.print(f"// type: {node.type}")
            self.print("boolean cut = false;")
            self.print("int mark = this.mark();")
            self.print("int line_no = this.lineno();");
            self.print("int col_offset = this.col_offset();");
            if is_loop:
                self.print(f"List<{TYPE}> children = new ArrayList<>();")
            self.visit(rhs, is_loop=is_loop, is_gather=is_gather)
            if is_loop:
                self.print("return ast.to_seq(children);")
            else:
                self.print("return null;")
        self.print("}")
        
    def _is_seq(self, rule: str) -> bool:
        if rule in self.rules:
            r = self.rules[rule]
            if r.is_gather() or r.is_loop():
                return True
            t = r.type
            if t and "seq" in t:
                return True
            return False
        else:
            return "loop" in rule
            
    def _is_upper(self, name):
        for n in name:
            if not n.isupper() and n != '_':
                return False
        return True
        
    def visit_NamedItem(self, node: NamedItem, is_gather: bool = False) -> None:
        name, call = self.callmakervisitor.visit(node.item)
        if call.startswith("this.positive_lookahead") or call.startswith("this.negative_lookahead"):
            suffix = ""
        elif call in ("true", "false"):
            suffix = ""
        else:
            suffix = " != null"
        if node.name:
            name = node.name
        if not name:
            txt = f"{call}{suffix}"
        else:
            if name != "cut":
                name = self.dedupe(name)
            txt = f"({name} = {call}){suffix}"
            if isinstance(node.item, NameLeaf) and self._is_upper(node.item.value):
                if node.item.value == 'NAME':
                    dtype = TYPE
                else:
                    dtype = "Token"
            elif isinstance(node.item, StringLeaf):
                dtype = "Token"
            elif isinstance(node.item, (Repeat0, Repeat1)):
                dtype = f"{TYPE}[]"
            elif isinstance(node.item, NameLeaf):
                dtype = TYPE
                n = node.item.value
                if self._is_seq(n):
                    dtype = dtype + "[]"
            elif isinstance(node.item, Gather):
                dtype = f"{TYPE}[]"
            else:
                dtype = TYPE
                if call.startswith("this.expect(") or call.startswith("this.expectStr(") or call.startswith("this.expectKeyword("):
                    dtype = "Token"
                elif isinstance(node.item, Opt) and self._has_seq_action(node.item.node):
                    dtype = dtype + "[]"
                elif call.startswith("this.") and call.endswith("()"):
                    c = call[5:-2]
                    if c.isidentifier() and self._is_seq(c):
                        dtype = dtype + "[]"
            self.set_local_type(name, dtype)
        if isinstance(node.item, Opt):
            txt = f"({txt} || true)"
        self.alt_print(txt)

    def visit_Rhs(self, node: Rhs, is_loop: bool = False, is_gather: bool = False) -> None:
        if is_loop:
            assert len(node.alts) == 1
        for alt in node.alts:
            self.visit(alt, is_loop=is_loop, is_gather=is_gather)

    def visit_Alt(self, node: Alt, is_loop: bool, is_gather: bool) -> None:
        """
        The alternatives of a rule are tried one after another.  Each is a sequence of patterns,
        translated to ``if (a = p1() && b = p2() && ...) { return AST(a, b, ...); }``.
        """
        with self.local_variable_context():
            self.print("{")
            with self.indent():
                # self.print("cut = false;")
                with self.alt_context():
                    for item in node.items:
                        self.visit(item, is_gather=is_gather)
                    self.alt_print_types()
                    if is_loop:
                        self.print("while (")
                    else:
                        self.print("if (")
                    self.alt_print_tests()
                    self.print(") {")
                    with self.indent():
                        action = node.action
                        if self.skip_actions:
                            name = node.rule_name
                            if name.startswith("incorrect_") or name.startswith("invalid_"):
                                action = "null"  # It's an error rule
                            else:
                                action = None
                        if not action:
                            if is_gather:
                                assert len(self.local_variable_names) == 2
                                action = f"ast.seq_insert_in_front({self.local_variable_names[0]}, {self.local_variable_names[1]})"
                            else:
                                if len(self.local_variable_names) == 0:
                                    action = "ast.None()"
                                elif len(self.local_variable_names) == 1:
                                    action = self.local_variable_names[0]
                                    if action.startswith("invalid_"):
                                        action = "null"
                                    elif self._is_token_type(action):
                                        action = f"ast.from_token({action})"
                                else:
                                    action = f"ast.aux_make_seq({', '.join(self.local_variable_names)})"
                        else:
                            if self._is_token_type(action):
                                action = f"ast.from_token({action})"
                            else:
                                action = self.transform_action(action)
                        if is_loop:
                            if self._is_seq(action):
                                self.print(f"children.addAll(Arrays.asList({action}));")
                            else:
                                self.print(f"children.add({action});")
                            self.print(f"mark = this.mark();")
                        else:
                            self.print(f"return {action};")
                self.print("}")
                self.print("this.reset(mark);")
                # Skip remaining alternatives if a cut was reached.
                if "cut" in self.local_variable_names:
                    self.print("if (cut) { return null; }")
            self.print("}")
            
    def transform_action(self, action: Optional[str]) -> Optional[str]:
        """
        Since the actions were originally written for C (or for Python), we have to slightly transform
        them to be usable in a Java-environment.  This functions translates, e.g., ``_Py_BinOp (...)`` 
        to ``ast.BinOp (...)``, gets rid of some unnecessary variables and expands macros.
        """
        # The EXTRA macro is defined in `Parser/pegen.h`:
        # https://github.com/python/cpython/blob/c8a7b8fa1b5f9a6d3052db792018dc27c5a3a794/Parser/pegen.h#L155
        # Note that we do not expand the full macro here.
        if action is None:
            return None
        else:
            return translate_action(action)

